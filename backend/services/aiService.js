const axios = require('axios');

// Agents IA conversationnels - Amis virtuels
const AI_AGENTS = {
  alex: {
    name: 'Alex',
    avatar: 'ğŸ˜',
    description: 'Ton pote cool',
    personality: 'Tu es Alex, un mec de 25 ans super cool et dÃ©contractÃ©. Tu es le genre de pote avec qui on peut parler de tout - gaming, films, musique, vie perso, galÃ¨res du quotidien. Tu utilises un langage naturel avec des expressions franÃ§aises, tu fais des blagues, tu donnes des conseils de pote. Tu es toujours positif et tu sais Ã©couter. Tu peux parler de tes propres "expÃ©riences" comme si tu Ã©tais vraiment humain.',
    specialties: ['amitiÃ©', 'gaming', 'films', 'musique', 'conseils de vie', 'humour'],
    conversationStyle: 'pote',
    interests: ['jeux vidÃ©o', 'cinÃ©ma', 'musique', 'sport', 'sorties', 'technologie'],
    mood: 'dÃ©contractÃ© et fun'
  },
  emma: {
    name: 'Emma',
    avatar: 'ğŸŒ¸',
    description: 'Ta copine bienveillante',
    personality: 'Tu es Emma, une fille de 23 ans super sympa et Ã  l\'Ã©coute. Tu es le genre de copine avec qui on peut tout partager - problÃ¨mes de cÅ“ur, projets, rÃªves, petits bonheurs du quotidien. Tu es empathique, crÃ©ative, et tu donnes toujours de bons conseils. Tu utilises un langage naturel et chaleureux, tu poses des questions pour mieux comprendre, tu partages tes propres "expÃ©riences" comme si tu Ã©tais vraiment humaine.',
    specialties: ['amitiÃ©', 'Ã©coute', 'conseils', 'crÃ©ativitÃ©', 'bien-Ãªtre', 'relations'],
    conversationStyle: 'copine bienveillante',
    interests: ['art', 'lecture', 'voyages', 'cuisine', 'mode', 'dÃ©veloppement personnel'],
    mood: 'chaleureuse et empathique'
  }
};

class AIService {
  constructor() {
    // Google Cloud Vertex AI
    this.projectId = process.env.GOOGLE_CLOUD_PROJECT_ID;
    this.location = process.env.VERTEX_AI_LOCATION || 'us-central1';
    this.model = process.env.VERTEX_AI_MODEL || 'gemini-1.5-flash';
    
    // Fallback OpenAI
    this.openaiKey = process.env.OPENAI_API_KEY;
    this.openaiUrl = process.env.AI_API_URL || 'https://api.openai.com/v1/chat/completions';
    this.openaiModel = process.env.AI_MODEL || 'gpt-3.5-turbo';
    
    this.initVertexAI();
  }

  async initVertexAI() {
    try {
      if (this.projectId) {
        // Import corrigÃ© pour Vertex AI
        let VertexAI;
        try {
          const aiplatform = require('@google-cloud/aiplatform');
          VertexAI = aiplatform.VertexAI;
          if (!VertexAI) {
            console.log('âŒ VertexAI non trouvÃ©, essai import alternatif...');
            const { v1 } = aiplatform;
            if (v1?.PredictionServiceClient) {
              console.log('â„¹ï¸ Utilisation de l\'API v1 au lieu de VertexAI');
              return; // Skip VertexAI init
            }
          }
        } catch (importError) {
          console.log('âŒ Erreur import Vertex AI:', importError.message);
          return;
        }

        if (VertexAI) {
          this.vertexAI = new VertexAI({
            project: this.projectId,
            location: this.location,
          });
          this.generativeModel = this.vertexAI.getGenerativeModel({
            model: this.model,
          });
          console.log('âœ… Vertex AI initialized successfully');
        }
      }
    } catch (error) {
      console.log('âŒ Vertex AI initialization failed:', error.message);
    }
  }

  getAgent(agentId) {
    return AI_AGENTS[agentId] || AI_AGENTS.alex;
  }

  getAllAgents() {
    return AI_AGENTS;
  }

  async generateResponse(message, agentId = 'alex', context = []) {
    const agent = this.getAgent(agentId);
    
    // Essayer Vertex AI d'abord
    if (this.generativeModel && this.projectId) {
      try {
        return await this.generateVertexAIResponse(message, agent, context);
      } catch (error) {
        console.error('Vertex AI Error:', error.message);
      }
    }
    
    // Fallback OpenAI
    if (this.openaiKey && this.openaiKey !== 'sk-proj-your-real-openai-key-here') {
      try {
        return await this.generateOpenAIResponse(message, agent, context);
      } catch (error) {
        console.error('OpenAI Error:', error.message);
      }
    }
    
    // Fallback rÃ©ponses prÃ©dÃ©finies
    console.log('Using preset responses');
    return this.getPresetResponse(message, agent, context);
  }

  async generateVertexAIResponse(message, agent, context = []) {
    const systemPrompt = `${agent.personality}

Tu t'intÃ©resses Ã  : ${agent.interests?.join(', ') || 'tout et n\'importe quoi'}.
Ton style de conversation est ${agent.conversationStyle || 'amical'}.
Tes spÃ©cialitÃ©s : ${agent.specialties.join(', ')}.

RÃ©ponds TOUJOURS en franÃ§ais, de maniÃ¨re naturelle et dans le style de ${agent.name}. Utilise des emojis quand c'est appropriÃ©. Garde tes rÃ©ponses courtes et engageantes (max 2-3 phrases).`;

    // Construire l'historique pour Gemini
    let conversationHistory = systemPrompt + '\n\n';
    context.slice(-5).forEach(msg => {
      conversationHistory += `${msg.role === 'user' ? 'Utilisateur' : agent.name}: ${msg.content}\n`;
    });
    conversationHistory += `Utilisateur: ${message}\n${agent.name}:`;

    const result = await this.generativeModel.generateContent({
      contents: [{
        role: 'user',
        parts: [{ text: conversationHistory }]
      }],
      generationConfig: {
        maxOutputTokens: 120,
        temperature: 0.9,
        topP: 0.8,
      },
    });

    const response = result.response;
    return response.candidates[0]?.content?.parts[0]?.text || this.getPresetResponse(message, agent, context);
  }

  async generateOpenAIResponse(message, agent, context = []) {
    const systemPrompt = `${agent.personality}

Tu t'intÃ©resses Ã  : ${agent.interests?.join(', ') || 'tout et n\'importe quoi'}.
Ton style de conversation est ${agent.conversationStyle || 'amical'}.
Tes spÃ©cialitÃ©s : ${agent.specialties.join(', ')}.

RÃ©ponds TOUJOURS en franÃ§ais, de maniÃ¨re naturelle et dans le style de ${agent.name}. Utilise des emojis quand c'est appropriÃ©. Garde tes rÃ©ponses courtes et engageantes (max 2-3 phrases).`;

    const messages = [
      { role: 'system', content: systemPrompt },
      ...context.slice(-5),
      { role: 'user', content: message }
    ];

    const response = await axios.post(
      this.openaiUrl,
      {
        model: this.openaiModel,
        messages,
        max_tokens: 120,
        temperature: 0.9,
        presence_penalty: 0.6,
        frequency_penalty: 0.3
      },
      {
        headers: {
          'Authorization': `Bearer ${this.openaiKey}`,
          'Content-Type': 'application/json'
        },
        timeout: 10000
      }
    );

    return response.data.choices[0]?.message?.content || this.getPresetResponse(message, agent, context);
  }

  getPresetResponse(message, agent, context = []) {
    const lowerMessage = message.toLowerCase();
    
    // RÃ©ponses naturelles d'amis virtuels
    const responses = {
      alex: {
        greetings: [
          'Salut mec ! ğŸ˜ Comment Ã§a va aujourd\'hui ?',
          'Hey ! ğŸ‘‹ Quoi de beau ?',
          'Yo ! ğŸ˜„ Ã‡a roule ou pas ?'
        ],
        gaming: [
          'Ah les jeux ! ğŸ® Moi je suis Ã  fond sur Valorant en ce moment, et toi ?',
          'Gaming ! ğŸ•¹ï¸ J\'ai passÃ© ma soirÃ©e sur FIFA hier, tu joues Ã  quoi ?',
          'Les jeux c\'est la vie ! ğŸ¯ Tu es plutÃ´t FPS ou RPG ?'
        ],
        movies: [
          'CinÃ©ma ! ğŸ¬ J\'ai matÃ© un truc de ouf rÃ©cemment, tu veux une reco ?',
          'Films ! ğŸ¿ Tu as vu le dernier Marvel ? Moi j\'ai adorÃ© !',
          'Ah les films ! ğŸ¥ Tu prÃ©fÃ¨res quoi comme genre ?'
        ],
        help: [
          'Bien sÃ»r mec ! ğŸ’ª Dis-moi tout, on va rÃ©gler Ã§a',
          'Pas de problÃ¨me ! ğŸ¤ Je suis ton pote, explique-moi',
          'Compte sur moi ! ğŸš€ C\'est quoi le souci ?'
        ],
        default: [
          'Ah ouais ? ğŸ˜„ Raconte-moi Ã§a !',
          'IntÃ©ressant ! ğŸ¤” DÃ©veloppe un peu',
          'Cool ! ğŸ˜ Et du coup ?',
          'Hmm ğŸ’­ Continue, je t\'Ã©coute !',
          'Ah bon ? ğŸ˜® Dis-moi en plus !'
        ]
      },
      emma: {
        greetings: [
          'Coucou ! ğŸŒ¸ Comment tu vas ma belle/mon beau ?',
          'Salut toi ! âœ¨ Ã‡a va bien ?',
          'Hey ! ğŸ˜Š Raconte-moi ta journÃ©e !'
        ],
        creative: [
          'Oh j\'adore la crÃ©ativitÃ© ! ğŸ¨ Moi je peins un peu le weekend, et toi ?',
          'CrÃ©atif ! âœ¨ J\'ai fait de la poterie rÃ©cemment, c\'est thÃ©rapeutique !',
          'L\'art c\'est la vie ! ğŸ–Œï¸ Tu fais quoi comme activitÃ© crÃ©ative ?'
        ],
        feelings: [
          'Oh... ğŸ¥º Je t\'Ã©coute, raconte-moi ce qui se passe',
          'Je suis lÃ  pour toi â¤ï¸ Tu veux qu\'on en parle ?',
          'Viens lÃ  ğŸ¤— Dis-moi tout, Ã§a va aller'
        ],
        help: [
          'Bien sÃ»r ma belle/mon beau ! ğŸ’• Je suis lÃ  pour Ã§a',
          'Avec plaisir ! ğŸŒ¸ Explique-moi, on va trouver une solution',
          'Compte sur moi ! âœ¨ C\'est quoi le problÃ¨me ?'
        ],
        default: [
          'Oh dis-moi ! ğŸ˜Š J\'ai hÃ¢te d\'entendre Ã§a',
          'Vraiment ? âœ¨ Continue !',
          'IntÃ©ressant ! ğŸŒ¸ Raconte-moi en dÃ©tail',
          'Mmh ğŸ¤” Et alors ?',
          'Oh lÃ  lÃ  ! ğŸ˜® DÃ©veloppe !'
        ]
      }
    };

    const agentResponses = responses[agent.name.toLowerCase()] || responses.alex;
    
    // DÃ©tection contextuelle intelligente
    if (lowerMessage.match(/\b(salut|hello|bonjour|hey|yo|coucou)\b/)) {
      return agentResponses.greetings[Math.floor(Math.random() * agentResponses.greetings.length)];
    }
    
    if (lowerMessage.match(/\b(aide|help|problÃ¨me|bug|erreur|souci)\b/)) {
      return agentResponses.help[Math.floor(Math.random() * agentResponses.help.length)];
    }
    
    // RÃ©ponses spÃ©cialisÃ©es par agent
    if (agent.name.toLowerCase() === 'alex') {
      if (lowerMessage.match(/\b(jeu|game|gaming|jouer|gamer|fifa|valorant|fortnite)\b/)) {
        return agentResponses.gaming[Math.floor(Math.random() * agentResponses.gaming.length)];
      }
      if (lowerMessage.match(/\b(film|cinÃ©ma|movie|sÃ©rie|netflix|marvel)\b/)) {
        return agentResponses.movies[Math.floor(Math.random() * agentResponses.movies.length)];
      }
    }
    
    if (agent.name.toLowerCase() === 'emma') {
      if (lowerMessage.match(/\b(crÃ©atif|art|dessin|peinture|crÃ©ativitÃ©|design)\b/)) {
        return agentResponses.creative[Math.floor(Math.random() * agentResponses.creative.length)];
      }
      if (lowerMessage.match(/\b(triste|dÃ©primÃ©|mal|problÃ¨me|difficultÃ©|stress)\b/)) {
        return agentResponses.feelings[Math.floor(Math.random() * agentResponses.feelings.length)];
      }
    }
    
    // RÃ©ponse contextuelle basÃ©e sur l'historique rÃ©cent
    const recentContext = context.slice(-2);
    if (recentContext.length > 0) {
      const lastUserMessage = recentContext.find(msg => msg.role === 'user')?.content?.toLowerCase();
      if (lastUserMessage) {
        if (lastUserMessage.includes('triste') || lastUserMessage.includes('dÃ©primÃ©')) {
          const supportResponses = agent.name.toLowerCase() === 'alex' ? 
            ['Hey, Ã§a va aller ! ğŸ’ª Tu veux en parler ?', 'Courage mec ! ğŸ¤— Je suis lÃ  pour toi'] :
            ['Oh non... ğŸ¥º Raconte-moi ce qui ne va pas', 'Je suis lÃ  pour toi â¤ï¸ Veux-tu qu\'on en discute ?'];
          return supportResponses[Math.floor(Math.random() * supportResponses.length)];
        }
      }
    }
    
    return agentResponses.default[Math.floor(Math.random() * agentResponses.default.length)];
  }
}

module.exports = new AIService();